def extract_data():
  import pandas as pd
  gdi = pd.read_csv('/content/drive/My Drive/TDK/TASK_3_data/curated_gene_disease_associations.tsv', sep = '\t')
  gdi = list(gdi[['geneId','diseaseId']].itertuples(index=False))
  import networkx as nx
  G = nx.from_edgelist(gdi)
  id_map = dict(zip(range(len(G.nodes())), G.nodes()))
  A = nx.to_scipy_sparse_matrix(G)
  import scipy.io as sio
  X = sio.loadmat('/content/drive/My Drive/TDK/TASK_3_data/features.mat')['features']
  return A, X, id_map


from scipy import sparse
import numpy as np

def mask_test_edges(A):
  A_triu = sparse.triu(A)
  edges = np.stack(A_triu.nonzero()).T # a gráf élei
  num_val = int(0.05 * edges.shape[0]) # 5% validációs él
  num_test = int(0.1 * edges.shape[0]) # 10% teszt él
  edge_ind = np.arange(edges.shape[0]) # az élek indexei
  np.random.shuffle(edge_ind) # megkeverjük az indexeket
  val_edge_ind = edge_ind[:num_val] # 5% alatt a validációs élek indexei
  test_edge_ind = edge_ind[num_val:(num_val + num_test)] # 5-15% között a teszt élek indexei
  train_edge_ind = edge_ind[(num_val + num_test):] # 15% felett a tanító élek indexei
  val_edges = edges[val_edge_ind]
  test_edges = edges[test_edge_ind]
  train_edges = edges[train_edge_ind]
  # a tanító mátrix
  arg1 = (np.ones(train_edges.shape[0]), (train_edges[:, 0], train_edges[:, 1]))
  A_train_triu = sparse.csr_matrix(arg1, shape=A.shape, dtype='float32')
  A_train = A_train_triu + A_train_triu.T
  edges = edges.tolist()
  str_edges = set(str(edge[0]) + " " + str(edge[1]) for edge in edges)
  str_test_edges_false = set()
  while len(str_test_edges_false) < len(test_edges): # annyi negatív teszt példát választunk, amennyi pozitív van
    ind_i = np.random.randint(0, A.shape[0])
    ind_j = np.random.randint(0, A.shape[0])
    if ind_i == ind_j: continue
    # ezeket már kiválasztottuk
    if str(ind_i) + " " + str(ind_j) in str_edges: continue
    if str(ind_j) + " " + str(ind_i) in str_edges: continue
    if str(ind_j) + " " + str(ind_i) in str_test_edges_false: continue
    if str(ind_i) + " " + str(ind_j) in str_test_edges_false: continue
    # ezeket hozzáadhatjuk
    str_test_edges_false.add(str(ind_i) + " " + str(ind_j))
  test_edges_false = []
  for str_edge_false in str_test_edges_false:
    edge_false = str_edge_false.split(" ")
    test_edges_false.append([int(edge_false[0]), int(edge_false[1])])

  val_edges_false = []
  while len(val_edges_false) < len(val_edges):  # annyi negatív validációs példát választunk, amennyi pozitív van
    ind_i = np.random.randint(0, A.shape[0])
    ind_j = np.random.randint(0, A.shape[0])
    if ind_i == ind_j: continue
    # ezeket már kiválasztottuk
    # if [ind_i, ind_j] in edges: continue
    # if [ind_j, ind_i] in edges: continue
    # if [ind_j, ind_i] in val_edges_false: continue
    # if [ind_i, ind_j] in val_edges_false: continue
    # ezeket hozzáadhatjuk
    val_edges_false.append([ind_i, ind_j])
  
  test_edges_false = np.array(test_edges_false)
  val_edges_false = np.array(val_edges_false)
  return A_train, val_edges, val_edges_false, test_edges, test_edges_false

A, X, id_map = extract_data()

A_train, val_edges, val_edges_false, test_edges, test_edges_false = mask_test_edges(A)

import tensorflow as tf
from scipy import sparse

# hyperparameters
hidden = 32
latent = 32
learning_rate = 0.01
batch_size = 5000
epochs = 30

def preprocess_support(A):
  N = A.shape[1]
  A_ = A + sparse.eye(N, dtype='float32')
  D = sparse.csr_matrix(A_.sum(axis=1))
  norm = D.power(-0.5)
  return A_.multiply(norm).T.multiply(norm)

def toTensorSparse(S):
  return tf.constant(S.todense())

def toTensor(T):
  return tf.constant(T)

class bilinear_layer:

  def __call__(self, tensor):
    return tf.linalg.matmul(tensor, tf.transpose(tensor))

class FC_layer:

  def __init__(self, indim, outdim):
    initial_value = tf.initializers.he_normal()((indim, outdim,))
    self.weight = tf.Variable(initial_value=initial_value, trainable=True)

  def __call__(self, tensor):
    return tf.linalg.matmul(tensor, self.weight)

class GC_layer:

  def __init__(self, indim, outdim):
    initial_value = tf.initializers.he_normal()((indim, outdim,))
    self.weight = tf.Variable(initial_value=initial_value, trainable=True)

  def __call__(self, tensor, support, test=False):
    if test:
      return support.dot(tensor.dot(self.weight.numpy()))
    else:
      return tf.linalg.matmul(support, tf.linalg.matmul(tensor, self.weight))


class Model:

  def __init__(self, size_tuple, optimizer):
    self.sources = []
    self.build(size_tuple)
    self.optimizer = optimizer
    self.μ = None
    self.logσ = None

  def build(self, size_tuple):
    X_dim, hidden, latent = size_tuple
    self.A_enc_layer = GC_layer(X_dim, hidden)
    self.A_μ_layer = GC_layer(hidden, latent)
    self.A_logσ_layer = GC_layer(hidden, latent)
    self.A_result_layer = bilinear_layer()
    self.X_enc_layer = GC_layer(X_dim, hidden)
    self.X_μ_layer = GC_layer(hidden, latent)
    self.X_logσ_layer = GC_layer(hidden, latent)
    self.X_result_layer = FC_layer(latent, X_dim)
    layers = [self.A_enc_layer, self.X_enc_layer, self.A_μ_layer, self.X_μ_layer, self.A_logσ_layer, self.X_logσ_layer]
    for layer in layers:
      self.sources += [layer.weight]
    self.sources += [self.X_result_layer.weight]
  
  def encode(self, X, support):
    A_enc = tf.nn.relu(self.A_enc_layer(X, support))
    A_μ = self.A_μ_layer(A_enc, support)
    A_logσ = self.A_logσ_layer(A_enc, support)
    X_enc = tf.nn.relu(self.X_enc_layer(X, support))
    X_μ = self.X_μ_layer(X_enc, support)
    X_logσ = self.X_logσ_layer(X_enc, support)
    return (A_μ + X_μ) / 2.0, (A_logσ + X_logσ) / 2.0

  def decode(self, sample):
    A_result = self.A_result_layer(sample)
    X_result = self.X_result_layer(sample)
    return A_result, X_result

  def predict(self, X, support):
    self.μ, self.logσ = self.encode(X, support)
    sample = self.μ + tf.math.exp(self.logσ) * tf.random.normal(self.logσ.shape)
    re_A, re_X = self.decode(sample)
    return re_A, re_X

  def embed(self, X, A):
    S = preprocess_support(A)
    A_enc = np.maximum(self.A_enc_layer(X, S, True), 0.0)
    A_μ = self.A_μ_layer(A_enc, S, True)
    X_enc = np.maximum(self.X_enc_layer(X, S, True), 0.0)
    X_μ = self.X_μ_layer(X_enc, S, True)
    return (A_μ + X_μ) / 2.0

  def train(self, X, A, val_edges, val_edges_false, batch_size, epochs):
    for epoch in range(epochs):

      if epoch % 10 == 0:
        self.μ = self.embed(X, A)
        # roc_auc, pr_auc = self.accuracy(val_edges, val_edges_false)
        # print(epoch, roc_auc, pr_auc)
        roc_auc, pr_auc = self.accuracy(test_edges, test_edges_false)
        print(epoch, roc_auc, pr_auc)

      a = np.arange(A.shape[1])
      p = np.squeeze(np.asarray(A.sum(axis=1))) / np.sum(np.squeeze(np.asarray(A.sum(axis=1))))
      nodes = np.random.choice(a, size=batch_size, replace=False, p=p).tolist()
      S_batch = toTensorSparse(preprocess_support(A[nodes].T[nodes]))
      A_batch = toTensor(A.T[nodes].T[nodes].todense())
      X_batch = tf.math.l2_normalize(toTensor(X[nodes]), axis=1)
      with tf.GradientTape() as tape:
        re_A, re_X = self.predict(X_batch, S_batch)
        losses = self.loss(A_batch, re_A, X_batch, re_X)
        loss_ = tf.reduce_sum(losses)
      print(epoch, [loss.numpy() for loss in losses], loss_.numpy())
      grads = tape.gradient(loss_, self.sources)
      self.optimizer.apply_gradients(zip(grads, self.sources))

  def test(self, X, A, test_edges, test_edges_false):
    self.μ = self.embed(X, A)
    roc_auc, pr_auc = self.accuracy(test_edges, test_edges_false)
    print(roc_auc, pr_auc)

  def re_A_loss(self, A, re_A):
    density = tf.reduce_sum(A) / tf.size(A, out_type=tf.float32)
    pos_weight = (1.0 - density) / density
    H_A = tf.nn.weighted_cross_entropy_with_logits(labels=A, logits=re_A, pos_weight=pos_weight) / (1.0 - density) / 2.0
    loss = tf.reduce_mean(H_A)
    return loss
  
  def re_X_loss(self, X, re_X):
    H_X = tf.losses.mse(X, re_X)
    loss = tf.reduce_mean(H_X)
    return loss

  def relative_entropy(self):
    H_S = (self.μ**2.0 + tf.math.exp(self.logσ)**2.0 - 2.0 * self.logσ - 1.0) / 2.0
    loss = tf.reduce_mean(H_S)
    return loss / 1000.0

  def weight_regularizer(self):
    decoder_weights = tf.concat([tf.reshape(source, -1) for source in self.sources[-1:]], axis=0)
    loss = tf.reduce_sum(decoder_weights**2.0)
    return loss / 1000.0

  def loss(self, A, re_A, X, re_X):
    return self.re_A_loss(A, re_A), self.re_X_loss(X, re_X), self.relative_entropy()#, self.weight_regularizer()

  def accuracy(self, edges_pos, edges_neg):
    re_pos = []
    for edge in edges_pos:
      re_pos.append(tf.nn.sigmoid(tf.reduce_sum(self.μ[edge[0],:] * self.μ[edge[1],:])))
    re_neg = []
    for edge in edges_neg:
      re_neg.append(tf.nn.sigmoid(tf.reduce_sum(self.μ[edge[0],:] * self.μ[edge[1],:])))
    re_all = tf.stack([re_pos, re_neg])
    all = tf.stack([tf.ones(len(re_pos)), tf.zeros(len(re_neg))])
    from sklearn.metrics import roc_auc_score, average_precision_score
    return roc_auc_score(all, re_all), average_precision_score(all, re_all)

N = A.shape[1]
X_dim = X.shape[1]

size_tuple = (X_dim, hidden, latent)
optimizer = tf.optimizers.Adam(learning_rate=learning_rate)

model = Model(size_tuple, optimizer)

model.train(X, A_train, val_edges, val_edges_false, batch_size, epochs)

model.test(X, A_train, test_edges, test_edges_false)
