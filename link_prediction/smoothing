!sudo apt-get install libmetis-dev
!pip install metis
import metis
import random
import tensorflow as tf
from scipy import sparse
import scipy.io as sio
import numpy as np

def mask_test_edges(A):
  A_triu = sparse.triu(A)
  edges = np.stack(A_triu.nonzero()).T # a gráf élei
  num_val = int(0.05 * edges.shape[0]) # 5% validációs él
  num_test = int(0.1 * edges.shape[0]) # 10% teszt él
  edge_ind = np.arange(edges.shape[0]) # az élek indexei
  np.random.shuffle(edge_ind) # megkeverjük az indexeket
  val_edge_ind = edge_ind[:num_val] # 5% alatt a validációs élek indexei
  test_edge_ind = edge_ind[num_val:(num_val + num_test)] # 5-15% között a teszt élek indexei
  train_edge_ind = edge_ind[(num_val + num_test):] # 15% felett a tanító élek indexei
  val_edges = edges[val_edge_ind]
  test_edges = edges[test_edge_ind]
  train_edges = edges[train_edge_ind]
  # a tanító mátrix
  arg1 = (np.ones(train_edges.shape[0]), (train_edges[:, 0], train_edges[:, 1]))
  A_train_triu = sparse.csr_matrix(arg1, shape=A.shape, dtype='float32')
  A_train = A_train_triu + A_train_triu.T
  edges = edges.tolist()
  str_edges = set(str(edge[0]) + " " + str(edge[1]) for edge in edges)
  str_test_edges_false = set()
  while len(str_test_edges_false) < len(test_edges): # annyi negatív teszt példát választunk, amennyi pozitív van
    ind_i = np.random.randint(0, A.shape[0])
    ind_j = np.random.randint(0, A.shape[0])
    if ind_i == ind_j: continue
    # ezeket már kiválasztottuk
    if str(ind_i) + " " + str(ind_j) in str_edges: continue
    if str(ind_j) + " " + str(ind_i) in str_edges: continue
    if str(ind_j) + " " + str(ind_i) in str_test_edges_false: continue
    if str(ind_i) + " " + str(ind_j) in str_test_edges_false: continue
    # ezeket hozzáadhatjuk
    str_test_edges_false.add(str(ind_i) + " " + str(ind_j))
  test_edges_false = []
  for str_edge_false in str_test_edges_false:
    edge_false = str_edge_false.split(" ")
    test_edges_false.append([int(edge_false[0]), int(edge_false[1])])

  val_edges_false = []
  while len(val_edges_false) < len(val_edges):  # annyi negatív validációs példát választunk, amennyi pozitív van
    ind_i = np.random.randint(0, A.shape[0])
    ind_j = np.random.randint(0, A.shape[0])
    if ind_i == ind_j: continue
    # ezeket már kiválasztottuk
    # if [ind_i, ind_j] in edges: continue
    # if [ind_j, ind_i] in edges: continue
    # if [ind_j, ind_i] in val_edges_false: continue
    # if [ind_i, ind_j] in val_edges_false: continue
    # ezeket hozzáadhatjuk
    val_edges_false.append([ind_i, ind_j])
  
  test_edges_false = np.array(test_edges_false)
  val_edges_false = np.array(val_edges_false)
  return A_train, val_edges, val_edges_false, test_edges, test_edges_false

filename = '/content/drive/My Drive/TDK/ppi.mat'

mat_dict = sio.loadmat(filename)
A = mat_dict['A']
X = mat_dict['X']
Y = mat_dict['Y']
train_mask = mat_dict['train_mask'][0].astype(bool)
val_mask = mat_dict['val_mask'][0].astype(bool)
test_mask = mat_dict['test_mask'][0].astype(bool)

A_train, val_edges, val_edges_false, test_edges, test_edges_false = mask_test_edges(A)

# hyperparameters
hidden = 512
latent = 256
learning_rate = 0.01
epochs = 100
nparts = 50
batch_size = 1

def cluster_graph(A, nparts):
  edge_cuts, parts = metis.part_graph([neighbors for neighbors in A.tolil().rows], nparts=nparts)
  print('Number of edge cuts: %d.' % edge_cuts)
  slices = {}
  for index, part in enumerate(parts):
    if part not in slices:
      slices[part] = []
    slices[part].append(index)
  return slices

slices = cluster_graph(A_train, nparts)

def preprocess_support(A):
  N = A.shape[1]
  A_ = A + sparse.eye(N, dtype='float32')
  D = sparse.csr_matrix(A_.sum(axis=1))
  norm = D.power(-0.5)
  return A_.multiply(norm).T.multiply(norm)

def toTensorSparse(S):
  return tf.constant(S.todense())

def toTensor(T):
  return tf.constant(T)

class bilinear_layer:

  def __init__(self, indim, outdim):
    initial_value = tf.initializers.he_normal()((indim, outdim,))
    self.weight = tf.Variable(initial_value=initial_value, trainable=True)

  def __call__(self, tensor):
    #return tf.linalg.matmul(tensor, tf.transpose(tensor))
    return tf.linalg.matmul(tensor, tf.linalg.matmul(self.weight, tf.transpose(tensor)))

class FC_layer:

  def __init__(self, indim, outdim):
    initial_value = tf.initializers.he_normal()((indim, outdim,))
    self.weight = tf.Variable(initial_value=initial_value, trainable=True)

  def __call__(self, tensor):
    return tf.linalg.matmul(tensor, self.weight)

class GC_layer:

  def __init__(self, indim, outdim):
    initial_value = tf.initializers.he_normal()((indim, outdim,))
    self.weight = tf.Variable(initial_value=initial_value, trainable=True)

  def __call__(self, tensor, support, test=False):
    if test:
      return support.dot(tensor.dot(self.weight.numpy()))
    else:
      return tf.linalg.matmul(support, tf.linalg.matmul(tensor, self.weight))

class Model:

  def __init__(self, size_tuple, optimizer):
    self.sources = []
    self.build(size_tuple)
    self.optimizer = optimizer
    self.μ = None
    self.logσ = None

  def build(self, size_tuple):
    X_dim, hidden, latent = size_tuple
    self.A_enc_layer = GC_layer(X_dim, hidden)
    self.A_μ_layer = GC_layer(hidden, latent)
    self.A_logσ_layer = GC_layer(hidden, latent)
    self.A_result_layer = bilinear_layer(latent, latent)
    self.X_enc_layer = GC_layer(X_dim, hidden)
    self.X_μ_layer = GC_layer(hidden, latent)
    self.X_logσ_layer = GC_layer(hidden, latent)
    self.X_result_layer = FC_layer(latent, X_dim)
    layers = [self.A_enc_layer, self.X_enc_layer, self.A_μ_layer, self.X_μ_layer, self.A_logσ_layer, self.X_logσ_layer] \
              + [self.X_result_layer] + [self.A_result_layer]
    for layer in layers:
      self.sources.append(layer.weight)
  
  def encode(self, X, S):
    A_enc = tf.nn.tanh(self.A_enc_layer(X, S))
    A_μ = self.A_μ_layer(A_enc, S)
    A_logσ = self.A_logσ_layer(A_enc, S)
    X_enc = tf.nn.tanh(self.X_enc_layer(X, S))
    X_μ = self.X_μ_layer(X_enc, S)
    X_logσ = self.X_logσ_layer(X_enc, S)
    return (A_μ + X_μ) * 0.5, (A_logσ + X_logσ) * 0.5

  def decode(self, sample):
    A_result = self.A_result_layer(sample)
    X_result = self.X_result_layer(sample)
    return A_result, X_result

  def predict(self, X, S):
    self.μ, self.logσ = self.encode(X, S)
    sample = self.μ + tf.math.exp(self.logσ) * tf.random.normal(self.logσ.shape)
    re_A, re_X = self.decode(sample)
    return re_A, re_X

  def embed(self, X, A):
    S = preprocess_support(A)
    A_enc = np.tanh(self.A_enc_layer(X, S, True))
    A_μ = self.A_μ_layer(A_enc, S, True)
    X_enc = np.tanh(self.X_enc_layer(X, S, True))
    X_μ = self.X_μ_layer(X_enc, S, True)
    return (A_μ + X_μ) * 0.5

  def train(self, X, A, val_edges, val_edges_false, slices, batch_size, epochs):
    for epoch in range(epochs):

      # self.μ = self.embed(X, A)
      # p = np.random.permutation(1000)
      # roc_auc, pr_auc = self.accuracy(val_edges[p], val_edges_false[p])
      # print(epoch, roc_auc, pr_auc)

      samples = random.sample(slices.keys(), batch_size)
      nodes = sum([slices[sample] for sample in samples], [])
      # import numpy as np
      # a = np.arange(A.shape[1])
      # p = np.squeeze(np.asarray(A.sum(axis=1))) / np.sum(np.squeeze(np.asarray(A.sum(axis=1))))
      # nodes = np.random.choice(a, size=5000, replace=False, p=p).tolist()
      S_batch = toTensorSparse(preprocess_support(A[nodes].T[nodes]))
      A_batch = toTensor(A.T[nodes].T[nodes].todense())
      X_batch = tf.math.l2_normalize(toTensor(X[nodes]), axis=1)
      with tf.GradientTape() as tape:
        re_A, re_X = self.predict(X_batch, S_batch)
        losses = self.loss(A_batch, re_A, X_batch, re_X)
        loss_ = tf.reduce_sum(losses)
        print(epoch, [loss.numpy() for loss in losses], loss_.numpy())
      grads = tape.gradient(loss_, self.sources)
      self.optimizer.apply_gradients(zip(grads, self.sources))

  def test(self, X, A, test_edges, test_edges_false):
    self.μ = self.embed(X, A)
    roc_auc, pr_auc = self.accuracy(test_edges, test_edges_false)
    print(roc_auc, pr_auc)
  
  def re_A_loss(self, A, re_A):
    density = tf.reduce_sum(A) / tf.size(A, out_type=tf.float32)
    pos_weight = (1.0 - density) / density
    H_A = tf.nn.weighted_cross_entropy_with_logits(labels=A, logits=re_A, pos_weight=pos_weight) / (1.0 - density) / 2.0
    loss = tf.reduce_mean(H_A)
    return loss
  
  def re_X_loss(self, X, re_X):
    H_X = tf.losses.mse(X, re_X)
    loss = tf.reduce_mean(H_X)
    return loss

  def relative_entropy(self):
    H_S = (self.μ**2.0 + tf.math.exp(self.logσ)**2.0 - 2.0 * self.logσ - 1.0) / 2.0
    loss = tf.reduce_mean(H_S)
    return loss / 1000.0

  def weight_regularizer(self):
    decoder_weights = tf.concat([tf.reshape(source, -1) for source in self.sources[-2:]], axis=0)
    loss = tf.reduce_sum(decoder_weights**2.0)
    return loss / 1000.0

  def loss(self, A, re_A, X, re_X):
    return self.re_A_loss(A, re_A), self.re_X_loss(X, re_X), self.relative_entropy()#, self.weight_regularizer()

  def accuracy(self, edges_pos, edges_neg):
    mat0 = self.μ
    mat1 = tf.linalg.matmul(self.μ, self.A_result_layer.weight)
    re_pos = []
    for edge in edges_pos:
      re_pos.append(tf.nn.sigmoid(tf.reduce_sum(mat0[edge[0],:] * mat1[edge[1],:])))
    re_neg = []
    for edge in edges_neg:
      re_neg.append(tf.nn.sigmoid(tf.reduce_sum(mat0[edge[0],:] * mat1[edge[1],:])))
    re_all = tf.stack([re_pos, re_neg])
    all = tf.stack([tf.ones(len(re_pos)), tf.zeros(len(re_neg))])
    from sklearn.metrics import roc_auc_score, average_precision_score
    return roc_auc_score(all, re_all), average_precision_score(all, re_all)

size_tuple = (X.shape[1], hidden, latent)
optimizer = tf.optimizers.Adam(learning_rate=learning_rate)

model = Model(size_tuple, optimizer)

model.train(X, A_train, val_edges, val_edges_false, slices, batch_size, epochs)

p = np.random.permutation(len(test_edges))

model.test(X, A_train, test_edges[p], test_edges_false[p])
